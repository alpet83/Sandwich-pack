<python file_id="5" mod_time="2025-07-15 12:56:33Z" relevance="0">
# /lib/document_block.py, created 2025-07-15 15:53 EEST
import logging
from typing import Dict
from lib.content_block import ContentBlock
from lib.sandwich_pack import SandwichPack

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s #%(levelname)s: %(message)s')

class DocumentBlock(ContentBlock):
    supported_types = ['.md', '.conf', '.toml', '.rulz']

    def __init__(self, content_text: str, content_type: str, file_name: str, timestamp: str, **kwargs):
        super().__init__(content_text, content_type, file_name, timestamp, **kwargs)
        self.tag = {
            '.md': 'markdown',
            '.conf': 'conf',
            '.toml': 'toml',
            '.rulz': 'rules'
        }.get(content_type, 'document')
        logging.debug(f"Initialized DocumentBlock with tag={self.tag}, content_type={content_type}, file_name={file_name}")

    def parse_content(self) -> Dict:
        return {
            "entities": [],
            "dependencies": {
                "imports": [],
                "modules": [],
                "calls": []
            }
        }

SandwichPack.register_block_class(DocumentBlock)
</python>
<python file_id="6" mod_time="2025-08-09 16:28:14Z" relevance="0">
# /lib/entity_parser.py, updated 2025-08-08 12:01 EEST
# Formatted with proper line breaks and indentation for project compliance.

import logging
import re
import traceback
from .llm_tools import estimate_tokens
from .iter_regex import IterativeRegex


def match_value(match, field: str, default=None):
    if field in match.groupdict() and match.group(field):
        return match.group(field)
    return default


def get_start_pos(match, field: str = "name"):
    return match.start(field) if field in match.groupdict() and match.group(field) else match.start()


class EntityParser:
    """Base class for parsing entities in content blocks."""

    def __init__(self, entity_type, owner, outer_regex: IterativeRegex, mask_pattern, inner_regex: IterativeRegex = None, default_visibility="public"):
        """Initialize parser with entity type, owner block, and iterative regex objects.

        Args:
            entity_type (str): Type of entity to parse (e.g., 'module', 'function').
            owner: ContentBlock or derivative instance (e.g., ContentCodeRust).
            outer_regex (IterativeRegex): Iterative regex for outer entities.
            mask_pattern (str): Regex pattern for masking entity tokens.
            inner_regex (IterativeRegex, optional): Iterative regex for inner entities.
            default_visibility (str): Default visibility if 'vis' group is absent ('public' or 'private').
        """
        self.entity_type = entity_type
        self.owner = owner
        self.content = owner.get_clean_content()
        self.outer_regex = outer_regex
        self.mask_pattern = mask_pattern
        self.inner_regex = inner_regex
        self.default_visibility = default_visibility
        self.new_entities_lines = []  # List of first_line numbers for new entities
        self.modules = []
        self.imports = {}  # Dict[entity_name: module_name]

        logging.debug(f"Initialized EntityParser for entity_type={entity_type}, file={owner.file_name}, default_visibility={default_visibility}")

    def _format_entity_name(self, match):
        name = match.group('name')
        prefix = self.owner.module_prefix
        if prefix and prefix in name:
            stack = "\t".join(traceback.format_stack(limit=5)).strip()
            logging.warning(f"module prefix {prefix} already included in {name}, stack:\n{stack}")
            return name
        return prefix + name

    def _format_inner_name(self, match, parent: str):
        return match.group('name')  # Default format for inner entity names

    def make_entity(self, e_type: str, name: str, vis: str, first_line: int, full_text: str, extra_fields: dict = None) -> dict:
        """Create an entity dictionary with bounds and token count.

        Args:
            e_type (str): Entity type (e.g., 'function', 'class', 'local_function').
            name (str): Entity name (e.g., 'my_function', 'MyClass::my_method').
            vis (str): Visibility ('public' or 'private').
            first_line (int): Starting line number.
            full_text (str): Full text of the entity.
            extra_fields (dict, optional): Additional fields to include (e.g., 'indent').

        Returns:
            dict: Entity dictionary with computed fields.
        """
        start_line = first_line
        last_line = start_line
        if not ("abstract" in e_type):
            start_line, last_line = self.owner.detect_bounds(first_line, self.owner.clean_lines)

        entity = {
            "type": e_type,
            "name": name,
            "visibility": vis,
            "file_id": self.owner.file_id,
            "first_line": start_line,
            "last_line": last_line,
            "tokens": estimate_tokens(full_text)
        }
        if extra_fields:
            entity.update(extra_fields)
        return entity

    def make_add_entity(self, e_type: str, name: str, vis: str, first_line: int, full_text: str, extra_fields: dict = None) -> bool:
        """Create and add an entity to entity_map.

        Args:
            e_type (str): Entity type.
            name (str): Entity name.
            vis (str): Visibility.
            first_line (int): Starting line number.
            full_text (str): Full text of the entity.
            extra_fields (dict, optional): Additional fields.

        Returns:
            bool: True if entity was added, False otherwise.
        """
        prev = self.owner.entity_map.get(first_line)
        if prev:
            logging.warning(f"Failed to add entity {name} at line {first_line}: already exists {prev} ")
            return False
        entity = self.make_entity(e_type, name, vis, first_line, full_text, extra_fields)
        if self.owner.add_entity(first_line, entity):
            self.new_entities_lines.append(first_line)
            return True
        logging.error(" add_entity failed")
        return False

    def detect_abstract(self, match):
        ending = match_value(match, 'ending', '')
        if ';' in ending or 'abstract' in match.group(0):
            return True if self else False
        return False

    def detect_visibility(self, match):
        return match_value(match, 'vis', self.default_visibility).strip()

    def _process_match(self, base_match):
        """Process a regex match to create and add an entity.

        Args:
            match: Regex match object with 'name' and optional 'vis' groups.
            start_line (int): Starting line number.
            full_text (str): Full text of the entity.

        Returns:
            bool: True if entity was added, False otherwise.
        """
        def_start = base_match.start()  # may include some lines before name location
        if def_start < 0:
            logging.warning(f"base match started at {def_start}")
            return
        start_pos = get_start_pos(base_match)  # name start for start_line (formal entity location)
        start_line = self.owner.find_line(start_pos)
        if start_line in self.owner.entity_map:
            logging.debug(f" Skipping line {start_line} for {self.entity_type} as it is already processed: {self.owner.entity_map[start_line]}")
            return

        clean_content = self.content
        validation = self.outer_regex.validate_match(clean_content, def_start)
        hit_rate = validation['hit_rate']
        if hit_rate < 0.5:
            logging.debug(f" Skipping low hit_rate {hit_rate} for match at {start_line}, offset{def_start}")
            return

        match = validation['match']
        def_end = match.end()
        full_text = self.owner.extract_entity_text(def_start, def_end)
        ent_lines = len(full_text.splitlines())
        vis = self.detect_visibility(match)
        name_final = self._format_entity_name(match)
        logging.debug(f"Processing entity {name_final} at line {start_line}, text lines {ent_lines}")
        spec = ''
        extra_fields = {"hit_rate": hit_rate}
        if match_value(match, "async"):
            spec += "async "
        if parent := match_value(match, "parent"):
            extra_fields["parent"] = parent.strip()

        if self.make_add_entity(spec + self.entity_type, name_final, vis, start_line, full_text, extra_fields):
            if self.inner_regex:
                self.parse_inner(full_text, start_line, name_final)
            return True
        return False

    def parse(self):
        """Parse clean_lines to extract entities and dependencies.

        Uses self.outer_regex to find entities and calls _process_match.
        Skips lines already processed by other parsers.

        Returns:
            bool: True if parsing was successful.
        """
        self.content = self.owner.get_clean_content()  # refresh, due masquerade acting
        if not self.content.strip():
            logging.debug("Attempt parsing void content")
            return False

        logging.debug(f"====================== Start parsing {self.entity_type} ======================= ")
        for base_match in self.outer_regex.all_matches(self.content):
            self._process_match(base_match)
        return True

    def parse_inner(self, content: str, offset: int, parent_name: str):
        """Parse inner entities (e.g., methods in traits or impls).

        Args:
            content (str): Content to parse (e.g., trait or impl block).
            offset (int): Line offset for inner entities.
            parent_name (str): Name of the parent entity (e.g., trait or impl name).

        Returns:
            None
        """
        if not self.inner_regex:
            return
        found = 0
        for base_match in self.inner_regex.all_matches(content):
            start_pos = base_match.start()  # initial start
            line_count = content[:start_pos].count('\n')
            method_line = offset + line_count

            validation = self.inner_regex.validate_match(content, start_pos)
            hit_rate = validation['hit_rate']
            if hit_rate < 0.4:
                logging.debug(f"Skipping low hit_rate {hit_rate} for inner match at {method_line}")
                continue
            match = validation['match']
            full_text_method = match.group(0).strip()
            head_len = len(full_text_method.splitlines())
            vis = self.detect_visibility(match)
            ent_type = "method"
            if self.detect_abstract(match):
                ent_type = "abstract " + ent_type
                logging.debug(f" detected abstract method {full_text_method}, {head_len} lines")

            if match_value(match, 'async'):
                ent_type = "async " + ent_type
            name = self._format_inner_name(match, parent_name)
            spec = match_value(match, 'spec')
            spec = spec + ' ' if spec else ''
            extra_fields = {"parent": parent_name, "hit_rate": hit_rate}

            entity = self.make_entity(spec + ent_type, name, vis, method_line, full_text_method, extra_fields=extra_fields)
            entity["last_line"] = max(entity["last_line"], method_line + head_len - 1)  # multi-line declaration of abstract method
            if self.owner.add_entity(method_line, entity):
                self.new_entities_lines.append(method_line)
                found += 1
            else:
                logging.warning(f"Failed to add inner entity {name} for {parent_name}")
        if found > 0:
            logging.debug(f" found inner {found} entities with parent {parent_name}")
        elif len(content) > 100:
            logging.debug(f" not found inner entities in:\n {content}")

    def masquerade(self):
        """Masquerade parsed entities in clean_lines.

        Replaces self.mask_pattern with entity['type'] for entity lines.

        Returns:
            list: Modified clean_lines.
        """
        clean_lines = self.owner.clean_lines.copy()
        if getattr(self, 'new_entities_lines', False):
            for line_num in self.new_entities_lines:
                e = self.owner.entity_map[line_num]
                clean_lines[line_num] = re.sub(self.mask_pattern, e['type'], clean_lines[line_num])
        return clean_lines

</python>
<python file_id="7" mod_time="2025-08-09 14:31:00Z" relevance="0">
# /lib/iter_regex.py, updated 2025-08-08 12:25 EEST
# Formatted with proper line breaks and indentation for project compliance.

import re
import logging


class IterativeRegex:
    """Iterative regex parser for modular pattern matching."""

    def __init__(self):
        """Initialize with empty token list."""
        self.tokens = []  # List of (regex_part: str, fields: list, detect_points: int)
        self.max_points = 0

    def add_token(self, regex_part: str, fields: list, detect_points: int):
        """Add a regex token with associated fields and weight.

        Args:
            regex_part (str): Partial regex pattern (e.g., r"impl\s+").
            fields (list): List of group names captured by this token (e.g., ["name"]).
            detect_points (int): Weight for hit_rate calculation.
        """
        try:
            re.compile(regex_part)  # Validate regex
            self.tokens.append((regex_part, fields, detect_points))
            self.max_points += detect_points
        except re.error as e:
            logging.error(f"Failed to compile regex token {regex_part}: {str(e)}")
            raise
        return self

    def all_matches(self, content_text: str):
        """Find all matches starting with the base token.

        Args:
            content_text (str): Text to parse.

        Returns:
            list: List of match objects for the base token.
        """
        if not self.tokens:
            logging.error("No tokens defined for matching")
            return []
        base_regex = self.tokens[0][0]  # First token is base
        try:
            matches = list(re.finditer(base_regex, content_text, re.MULTILINE))
            if matches:
                logging.debug(f"Found {len(matches)} base matches for {base_regex}")
            else:
                logging.debug(f"No base matches for {base_regex} in {content_text.strip()}")
            return matches
        except re.error as e:
            logging.error(f"Failed to match base regex {base_regex}: {str(e)}")
            return []

    def validate_match(self, content_text: str, start_offset: int):
        """Validate a match by applying a full regex from tokens up to the current iteration.

        Args:
            content_text (str): Full text to validate against.
            start_offset (int): Starting position of the base match.

        Returns:
            dict: {'match': match object, 'hit_rate': float, 'end_offset': int}
        """
        if not self.tokens:
            logging.error("No tokens defined for validation")
            return {'match': None, 'hit_rate': 0.0, 'end_offset': start_offset}
        assert start_offset >= 0, f"invalid start offset {start_offset}"
        total_points = 0
        last_match = None
        end_offset = start_offset
        current_points = 0
        full_regex = ""
        best_regex = ""
        line = content_text[start_offset:].splitlines()[0]
        for i, token in enumerate(self.tokens, 1):
            # Build full regex up to current token
            full_regex += token[0]
            current_points += token[2]
            try:
                found = None
                present = []
                matches = list(re.finditer(full_regex, content_text, re.MULTILINE))
                for match in matches:
                    loc = match.start()
                    if loc == start_offset:
                        found = match
                        break
                    else:
                        present.append(loc)
                if found:
                    last_match = found
                    total_points = current_points
                    end_offset = found.end()
                    best_regex = full_regex
                else:
                    logging.debug(f"\t#{i} Failed full regex {full_regex} at offset {start_offset}, line: {line}. Present only at {present}")
                    break
            except re.error as e:
                logging.error(f"Error matching full regex {full_regex}: {str(e)}")
                break

        if best_regex:
            logging.debug(f" \t Matched best regex {best_regex}, points: {total_points}, end_offset: {end_offset}")

        hit_rate = total_points / self.max_points if self.max_points > 0 else 0.0
        return {
            'match': last_match,
            'hit_rate': hit_rate,
            'end_offset': end_offset
        }
</python>
<python file_id="8" mod_time="2025-08-09 15:41:29Z" relevance="0">
# /lib/js_block.py, updated 2025-08-08 18:45 EEST
# Formatted with proper line breaks and indentation for project compliance.

import re
import os
import logging
import traceback
from pathlib import Path
from lib.content_block import ContentBlock, estimate_tokens
from lib.sandwich_pack import SandwichPack
from lib.entity_parser import EntityParser, match_value
from lib.deps_builder import DepsParser
from lib.iter_regex import IterativeRegex

INDENT_PART = r"^(?P<indent>[ \t]*)(?:import\s+)?"
EXPORT_PART = r"(?:export\s+(?:default\s+)?)?"
BASE_REGEX_PATTERN = INDENT_PART + EXPORT_PART
FN_VARIANTS = [r"(?:function\s+(?P<name>\w+)\s*\((?P<args>[^\)]*)\)",
               r"const\s+(?P<name2>\w+)\s*=\s*(?:async\s+)?function\s*\w*\s*\((?P<args2>[^\)]*)\)",
               r"const\s+(?P<name3>\w+)\s*=\s*\((?P<args3>[^\)]*)\)\s*=>)"]

FN_REGEX_PATTERN = r"(?:const\s+(?P<name>\w+)\s*=\s*)?(?P<async>async\s+)?(?:function\s*(?P<name2>\w+)?)?\("
CLASS_REGEX_PATTERN = r"class\s+(?P<name>\w+)"
INTERFACE_REGEX_PATTERN = r"interface\s+(?P<name>\w+)"
OBJECT_REGEX_PATTERN = r"const\s+(?P<name>\w+)\s*="
METHODS_REGEX_PATTERN = r"(?:methods|computed|watch)\s*:"

class ObjectParser(EntityParser):
    """Parser for JavaScript object declarations."""
    def __init__(self, entity_type, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(BASE_REGEX_PATTERN + OBJECT_REGEX_PATTERN, ["indent", "name"], 2)
        outer_regex.add_token(r"\s*{", ["head_end"], 1)
        super().__init__(entity_type, owner, outer_regex, r"\bconst\b|\bexport\b", default_visibility="public")

    def _format_entity_name(self, match):
        name = match.group('name') or "default"
        return self.owner.module_prefix + name

    def parse(self):
        content = self.owner.get_clean_content()
        for base_match in self.outer_regex.all_matches(content):
            start_pos = base_match.start()
            start_line = self.owner.find_line(start_pos)
            validation = self.outer_regex.validate_match(content, start_pos)
            if validation['hit_rate'] < 0.5:
                logging.debug(f"Skipping low hit_rate {validation['hit_rate']} for match at {start_line}")
                continue
            match = validation['match']
            if not match:
                continue
            name = self._format_entity_name(match)
            vis = self.default_visibility
            full_text = self.owner.extract_entity_text(match.start(), match.end())
            extra_fields = {"parent": ""}
            self.make_add_entity(self.entity_type, name, vis, start_line, full_text, extra_fields)
        return True


class MethodParser(EntityParser):
    """Parser for JavaScript methods inside objects."""
    def __init__(self, entity_type, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(
            r"^(?P<indent>[ \t]*)(?P<spec>" + METHODS_REGEX_PATTERN + r")", ["indent", "spec", "name", "args"], 2
        ).add_token(r"\s*{", ["head_end"], 1)
        super().__init__(entity_type, owner, outer_regex, r"\bmethods\b|\bcomputed\b|\bwatch\b|\bfn\b", default_visibility="public")
        self.inner_regex = IterativeRegex()
        self.inner_regex.add_token(
            r"^\s*(?P<name>\w+)\s*\((?P<args>[^)]*)\)", ["name", "args"], 2
        ).add_token(
            r"\s*{", ['head_end'], 1
        )

    def _format_entity_name(self, match):
        return "methods" if self else "trash"

    def parse(self):
        # TODO: AI generated strange code, need reintegration to ObjectParser
        content = self.owner.get_clean_content()
        for base_match in self.outer_regex.all_matches(content):
            start_pos = base_match.start()
            start_line = self.owner.find_line(start_pos)
            validation = self.outer_regex.validate_match(content, start_pos)
            if validation['hit_rate'] < 0.5:
                logging.debug(f"Skipping low hit_rate {validation['hit_rate']} for match at {start_line}")
                continue
            match = validation['match']
            if not match:
                continue
            indent = len(match_value(match, 'indent', ''))
            parent = ""
            for line_num in range(start_line - 1, 0, -1):
                line = self.owner.clean_lines[line_num]
                if not isinstance(line, str) or not line.strip():
                    continue
                line_indent = len(line) - len(line.lstrip())
                if line_indent < indent and '{' in line:
                    parent_entity = self.owner.entity_map.get(line_num, {})
                    if parent_entity.get('type') == 'object':
                        parent = parent_entity['name']
                        break

            full_text = self.owner.extract_entity_text(match.start(), match.end())
            logging.debug(f"Methods part: {full_text}")
            self.parse_inner(full_text, start_line, parent)
            # self.make_add_entity(self.entity_type, name, vis, start_line, full_text, extra_fields)
        return True


class FunctionParser(EntityParser):
    """Parser for JavaScript functions."""
    def __init__(self, entity_type, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(
            BASE_REGEX_PATTERN + FN_REGEX_PATTERN, ["indent", "async", "name", "name2"], 2
        ).add_token(
            r"(?P<args>[^\)]*)\)(?:\s*=>)?\s*{", ["args"], 1
        ).add_token(r"\s*{", ["head_end"], 1)
        super().__init__(entity_type, owner, outer_regex, r"\bfunction\b|\bconst\b", default_visibility="public")

    def _format_entity_name(self, match):
        return match.group('name') or match.group('name2') or match.group('name3')

    def parse(self):
        content = self.owner.get_clean_content()
        for base_match in self.outer_regex.all_matches(content):
            start_pos = base_match.start()   # begin of declaration
            start_line = self.owner.find_line(start_pos)
            validation = self.outer_regex.validate_match(content, start_pos)
            if validation['hit_rate'] < 0.5:
                logging.debug(f"Skipping low hit_rate {validation['hit_rate']} for match at {start_line}")
                continue
            match = validation['match']
            if not match:
                continue
            name = self._format_entity_name(match)
            full_text = self.owner.extract_entity_text(match.start(), match.end())
            extra_fields = {"parent": ""}
            self.make_add_entity(self.entity_type, self.owner.module_prefix + name, self.default_visibility, start_line, full_text, extra_fields)
        return True


class InterfaceParser(EntityParser):
    """Parser for TypeScript interfaces."""
    def __init__(self, entity_type, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(BASE_REGEX_PATTERN + INTERFACE_REGEX_PATTERN, ["indent", "vis", "name"], 2)
        outer_regex.add_token(r"\s+extends\s+(?P<parent>\w+)", ["parent"], 1)
        outer_regex.add_token(r"\s*{", ["head_end"], 1)
        super().__init__(entity_type, owner, outer_regex, r"\binterface\b", default_visibility="public")


class ClassParser(EntityParser):
    """Parser for JavaScript/TypeScript classes."""
    def __init__(self, entity_type, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(BASE_REGEX_PATTERN + CLASS_REGEX_PATTERN, ["indent", "vis", "name"], 2)
        outer_regex.add_token(r"\s+extends\s+(?P<parent>\w+)", ["parent"], 1)
        outer_regex.add_token(r"\s*{", ["head_end"], 1)
        super().__init__(entity_type, owner, outer_regex, r"\bclass\b", default_visibility="public")


class DepsParserJs(DepsParser):
    """Parser for JavaScript/TypeScript imports."""
    def __init__(self, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(r"^(?P<indent>[ \t]*)import\s+{?(?P<items>[\w,\s]+)}?\s+from\s+['\"](?P<module>[^'\"]+)['\"]", ["indent", "items", "module"], 2)
        inner_regex = IterativeRegex()
        inner_regex.add_token(r"(?P<name>\w+)\s*(?:,|$)", ["name"], 1)
        super().__init__(owner, outer_regex)
        self.inner_regex = inner_regex

    def _process_match(self, match):
        module = match.group('module')
        if module:
            self.add_module(module)
        items = match.group('items')
        if items:
            content = items.strip()
            for inner_match in self.inner_regex.all_matches(content):
                validation = self.inner_regex.validate_match(content, inner_match.start())
                if validation['hit_rate'] < 0.5:
                    continue
                inner_match = validation['match']
                if inner_match:
                    item = inner_match.group('name')
                    self.add_import(module, item)


class ContentCodeJs(ContentBlock):
    """Parser for JavaScript content blocks."""
    supported_types = [".js"]

    def __init__(self, content_text: str, content_type: str, file_name: str, timestamp: str, **kwargs):
        super().__init__(content_text, content_type, file_name, timestamp, **kwargs)
        self.tag = "js"
        self.open_ml_string = ["`"]
        self.close_ml_string = ["`"]
        self.entity_map = {}
        self.module_prefix = kwargs.get("module_prefix", "")
        logging.debug(f"Initialized ContentCodeJs with tag={self.tag}, file_name={file_name}, module_prefix={self.module_prefix}")

    def parse_content(self, clean_lines=None, depth=0):
        """Parses JavaScript content to extract entities and dependencies."""
        logging.debug(f"Parsing content at depth {depth} for file {self.file_name}")
        if depth >= 2:
            self.parse_warn(f"Maximum recursion depth reached for file {self.file_name}")
            return {"entities": [], "dependencies": {"modules": [], "imports": {}}}
        self.entity_map = {}
        self.dependencies = {"modules": [], "imports": {}}
        self.clean_lines = clean_lines if clean_lines is not None else ([""] + self.content_text.splitlines())
        self.strip_strings()
        self.strip_comments()

        parsers = [
            FunctionParser("function", self),
            ObjectParser("object", self),
            MethodParser("method", self),
            DepsParserJs(self)
        ]

        original_clean_lines = self.clean_lines.copy()
        for parser in parsers:
            try:
                self.clean_lines = original_clean_lines.copy()
                if parser.parse():
                    self.extend_deps(parser)
                    self.clean_lines = parser.masquerade()
                    logging.debug(f"Applied {parser.__class__.__name__} parser, new clean_lines[1:10]: {self.clean_lines[1:10]}")
            except Exception as e:
                logging.error(f"Error in {parser.__class__.__name__} parser for {self.file_name}: {str(e)}")
                traceback.print_exc()
                break

        self.clean_lines = original_clean_lines
        entities = self.sorted_entities()
        logging.debug(f"Parsed {len(entities)} entities in {self.file_name}")
        return {"entities": entities, "dependencies": self.dependencies}


class ContentCodeTypeScript(ContentCodeJs):
    """Parser for TypeScript content blocks."""
    supported_types = [".ts"]

    def __init__(self, content_text: str, content_type: str, file_name: str, timestamp: str, **kwargs):
        super().__init__(content_text, content_type, file_name, timestamp, **kwargs)
        self.tag = "tss"
        logging.debug(f"Initialized ContentCodeTypeScript with tag={self.tag}, file_name={file_name}, module_prefix={self.module_prefix}")

    def parse_content(self, clean_lines=None, depth=0):
        """Parses TypeScript content to extract entities and dependencies."""
        logging.debug(f"Parsing content at depth {depth} for file {self.file_name}")
        if depth >= 2:
            self.parse_warn(f"Maximum recursion depth reached for file {self.file_name}")
            return {"entities": [], "dependencies": {"modules": [], "imports": {}}}
        self.entity_map = {}
        self.dependencies = {"modules": [], "imports": {}}
        self.clean_lines = clean_lines if clean_lines is not None else ([""] + self.content_text.splitlines())
        self.strip_strings()
        self.strip_comments()

        parsers = [
            FunctionParser("function", self),
            ObjectParser("object", self),
            MethodParser("method", self),
            InterfaceParser("interface", self),
            ClassParser("class", self),
            DepsParserJs(self)
        ]

        original_clean_lines = self.clean_lines.copy()
        for parser in parsers:
            try:
                self.clean_lines = original_clean_lines.copy()
                if parser.parse():
                    self.extend_deps(parser)
                    self.clean_lines = parser.masquerade()
                    logging.debug(f"Applied {parser.__class__.__name__} parser, new clean_lines[1:10]: {self.clean_lines[1:10]}")
            except Exception as e:
                logging.error(f"Error in {parser.__class__.__name__} parser for {self.file_name}: {str(e)}")
                traceback.print_exc()
                break

        self.clean_lines = original_clean_lines
        entities = self.sorted_entities()
        logging.debug(f"Parsed {len(entities)} entities in {self.file_name}")
        return {"entities": entities, "dependencies": self.dependencies}


SandwichPack.register_block_class(ContentCodeJs)
SandwichPack.register_block_class(ContentCodeTypeScript)
</python>
<python file_id="9" mod_time="2025-08-05 09:55:32Z" relevance="0">

import logging
import re
import math


def estimate_tokens(content):
    """Estimates tokens by counting words and spaces more accurately."""
    if not content:
        return 0
    tokens = 0
    words = re.findall(r'\S+', content)
    for word in words:
        if len(word) >= 5:
            tokens += math.ceil(len(word) / 4)
        else:
            tokens += 1
    spaces = len(re.findall(r'\s+', content))
    tokens += spaces
    logging.debug("Estimated tokens for content (length=%d): %d tokens (words=%d, spaces=%d)",
                  len(content), tokens, len(words), spaces)
    return tokens

</python>
<python file_id="10" mod_time="2025-08-09 16:38:40Z" relevance="0">
# /lib/php_block.py, updated 2025-08-08 18:30 EEST
# Formatted with proper line breaks and indentation for project compliance.

import re
import os
import logging
import traceback
from pathlib import Path
from lib.content_block import ContentBlock, estimate_tokens
from lib.sandwich_pack import SandwichPack
from lib.entity_parser import EntityParser, match_value
from lib.deps_builder import DepsParser
from lib.iter_regex import IterativeRegex

BASE_REGEX_PATTERN = r"^(?P<indent>[ \t]*)(?P<vis>public\s+|protected\s+|private\s+)?"
ARGS_REGEX_PATTERN = r"(?P<args>[\^)]*)"


callable_regex = IterativeRegex()
callable_regex.add_token(
    BASE_REGEX_PATTERN + r"function\s+(?P<name>\w+)\s*\(",
    ["indent", "vis", "name"], 2
).add_token(
    ARGS_REGEX_PATTERN + r"\)", ["args"], 1
).add_token(
    r"\s*(?P<ending>{|;)", ["head_end"], 1
)


class ClassParser(EntityParser):
    """Parser for PHP classes and their methods."""
    def __init__(self, entity_type, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(
            BASE_REGEX_PATTERN + r"class\s+(?P<name>\w+)(?P<parent>\s+extends\s+\w+)?",
            ["indent", "vis", "name"], 2
        ).add_token(
            r"\s*:", ["head_end"], 1
        )
        super().__init__(entity_type, owner, outer_regex, r"\bclass\b", inner_regex=callable_regex, default_visibility="public")


class FunctionParser(EntityParser):
    """Parser for PHP functions."""
    def __init__(self, entity_type, owner):
        super().__init__(entity_type, owner, callable_regex, r"\bfunction\b", default_visibility="public")


class DepsParserPHP(DepsParser):
    """Parser for PHP imports."""
    def __init__(self, owner):
        outer_regex = IterativeRegex()
        outer_regex.add_token(
            r"^(?P<indent>[ \t]*)(require|include|require_once|include_once)\s+",
            ["indent", "base"], 2
        ).add_token(
            r"\(*\s*['\"]+(?P<module>\w+).php['\"]+\)*", ["module"], 1
        )
        super().__init__(owner, outer_regex)

    def _process_match(self, match):
        validation = self.outer_regex.validate_match(self.content, match.start())
        hit_rate = validation['hit_rate']
        if hit_rate < 0.5:
            return
        module = match_value(validation["match"], 'module')
        if module:
            self.add_module(module)

class ContentCodePHP(ContentBlock):
    """Parser for PHP content blocks."""
    supported_types = [".php"]

    def __init__(self, content_text: str, content_type: str, file_name: str, timestamp: str, **kwargs):
        super().__init__(content_text, content_type, file_name, timestamp, **kwargs)
        self.tag = "php"
        self.raw_quote_char = "'"
        self.string_quote_chars = "\"'"
        self.open_ml_string = []
        self.close_ml_string = []
        self.open_sl_comment = ["//", "#"]
        self.open_ml_comment.append(r"\?>")
        self.close_ml_comment.append(r"<\?php")
        self.escape_char = "\\"
        self.entity_map = {}
        self.module_prefix = kwargs.get("module_prefix", "")
        logging.debug(f"Initialized ContentCodePHP with tag={self.tag}, file_name={file_name}, module_prefix={self.module_prefix}")



    def strip_strings(self):
        """Strips string literals from PHP content, preserving module names in require/include."""
        if len(self.clean_lines) <= 1:
            raise Exception("clean_lines not filled")
        content = self.content_text

        #  Very matter quotes duplication for import lines
        protected_content = re.sub(
            r"^(?P<indent>[ \t]*)(require|include|require_once|include_once)\s+\(*['\"]([^'^\"]+)['\"]\)*",
            r'\g<indent>\g<2> ""\g<3>"" // import preserved',
            content,
            flags=re.MULTILINE
        )
        self.clean_lines = [''] + protected_content.splitlines()
        super().strip_strings()


    def check_raw_escape(self, line: str, position: int, quote_char: str) -> bool:
        """Checks if the character at position is part of a PHP raw string escape sequence."""
        if position + 1 < len(line) and line[position] == self.escape_char:
            next_char = line[position + 1]
            return next_char == quote_char or next_char == self.escape_char
        return False

    def parse_content(self, clean_lines=None, depth=0):
        """Parses PHP content to extract entities and dependencies."""
        logging.debug(f"Parsing content at depth {depth} for file {self.file_name}")
        if depth >= 2:
            self.parse_warn(f"Maximum recursion depth reached for file {self.file_name}")
            return {"entities": [], "dependencies": {"modules": [], "imports": {}}}
        self.entity_map = {}
        self.dependencies = {"modules": [], "imports": {}}
        self.clean_lines = clean_lines if clean_lines is not None else ([""] + self.content_text.splitlines())
        self.strip_strings()
        self.strip_comments()

        parsers = [
            ClassParser("class", self),
            FunctionParser("function", self),
            DepsParserPHP(self)
        ]
        self.parsers = parsers

        original_clean_lines = self.clean_lines.copy()
        for parser in parsers:
            try:
                self.clean_lines = original_clean_lines.copy()
                if parser.parse():
                    self.extend_deps(parser)
                    self.clean_lines = parser.masquerade()
                    logging.debug(f"Applied {parser.__class__.__name__} parser, new clean_lines[1:10]: {self.clean_lines[1:10]}")
            except Exception as e:
                logging.error(f"Error in {parser.__class__.__name__} parser for {self.file_name}: {str(e)}")
                traceback.print_exc()
                break

        self.clean_lines = original_clean_lines
        entities = self.sorted_entities()
        logging.debug(f"Parsed {len(entities)} entities in {self.file_name}")
        return {"entities": entities, "dependencies": self.dependencies}


SandwichPack.register_block_class(ContentCodePHP)
</python>

INDEX_COPY:
{
  "packer_version": "0.6",
  "context_date": "2025-08-09 16:40:12Z",
  "templates": {
    "filelist": "file_id,file_name,md5,tokens,timestamp",
    "users": "user_id,username,role",
    "entities": "vis(pub/prv),type,parent,name,file_id,start_line-end_line,tokens"
  },
  "project_name": "sandwich_pack",
  "datasheet": {
    "project_root": "/app",
    "backend_address": "http://localhost:8080",
    "frontend_address": "http://vps.vpn:8008",
    "resources": {
      "database": "sqlite:///app/data/multichat.db",
      "log_file": "/app/logs/colloquium_core.log"
    }
  },
  "entities": [
    "pub,function,,get_file_mod_time,0,11-14,54",
    "pub,function,,is_hidden_file,0,16-17,30",
    "pub,function,,collect_files,0,19-71,493",
    "pub,function,,main,0,73-106,333",
    "pub,function,,verify_sandwiches,1,14-75,486",
    "pub,class,ABC,CodeStripper,2,10-104,878",
    "prv,method,CodeStripper,__init__,2,12-19,68",
    "pub,method,CodeStripper,detect_single,2,21-24,36",
    "pub,method,CodeStripper,detect_multi_open,2,26-29,24",
    "pub,method,CodeStripper,detect_multi_close,2,31-34,37",
    "pub,method,CodeStripper,strip,2,36-104,687",
    "pub,class,CodeStripper,CodeStringStripper,2,106-166,740",
    "pub,class,CodeStripper,CodeCommentStripper,2,168-198,392",
    "pub,class,,ContentBlock,3,22-384,3724",
    "prv,method,ContentBlock,__init__,3,25-54,360",
    "pub,method,ContentBlock,parse_warn,3,56-59,27",
    "pub,method,ContentBlock,strip_strings,3,61-78,175",
    "pub,method,ContentBlock,strip_comments,3,80-94,136",
    "pub,method,ContentBlock,save_clean,3,96-108,144",
    "pub,method,ContentBlock,get_clean_content,3,110-121,105",
    "pub,method,ContentBlock,find_line,3,123-130,81",
    "pub,method,ContentBlock,count_chars,3,132-142,109",
    "pub,method,ContentBlock,sorted_entities,3,144-152,87",
    "pub,method,ContentBlock,detect_bounds,3,154-178,271",
    "pub,method,ContentBlock,check_entity_placement,3,180-200,240",
    "pub,method,ContentBlock,add_entity,3,202-217,190",
    "pub,method,ContentBlock,extract_entity_text,3,219-228,132",
    "pub,method,ContentBlock,extend_deps,3,230-241,118",
    "pub,method,ContentBlock,full_text_replace,3,243-273,371",
    "pub,method,ContentBlock,compress,3,275-360,973",
    "pub,method,ContentBlock,to_sandwich_block,3,362-381,156",
    "pub,method,ContentBlock,parse_content,3,383-384,30",
    "pub,class,EntityParser,DepsParser,4,11-36,226",
    "prv,method,DepsParser,__init__,4,13-16,58",
    "pub,method,DepsParser,add_module,4,18-22,44",
    "pub,method,DepsParser,add_import,4,24-28,47",
    "pub,method,DepsParser,store_deps,4,30-36,64",
    "pub,function,,organize_modules,4,39-100,629",
    "pub,local_function,,dfs,4,67-77,20",
    "pub,class,ContentBlock,DocumentBlock,5,9-30,173",
    "prv,method,DocumentBlock,__init__,5,12-20,105",
    "pub,method,DocumentBlock,parse_content,5,22-30,42",
    "pub,function,,match_value,6,11-14,53",
    "pub,function,,get_start_pos,6,17-18,53",
    "pub,class,,EntityParser,6,21-258,2486",
    "prv,method,EntityParser,__init__,6,24-46,340",
    "prv,method,EntityParser,_format_entity_name,6,48-55,88",
    "prv,method,EntityParser,_format_inner_name,6,57-58,26",
    "pub,method,EntityParser,make_entity,6,60-90,333",
    "pub,method,EntityParser,make_add_entity,6,92-115,273",
    "pub,method,EntityParser,detect_abstract,6,117-121,67",
    "pub,method,EntityParser,detect_visibility,6,123-124,32",
    "prv,method,EntityParser,_process_match,6,126-172,470",
    "pub,method,EntityParser,parse,6,174-191,152",
    "pub,method,EntityParser,parse_inner,6,193-243,559",
    "pub,method,EntityParser,masquerade,6,245-258,136",
    "pub,class,,IterativeRegex,7,8-113,846",
    "prv,method,IterativeRegex,__init__,7,11-14,27",
    "pub,method,IterativeRegex,add_token,7,16-31,170",
    "pub,method,IterativeRegex,all_matches,7,33-55,165",
    "pub,method,IterativeRegex,validate_match,7,57-113,474",
    "pub,class,EntityParser,ObjectParser,8,28-57,358",
    "prv,method,ObjectParser,__init__,8,30-34,87",
    "prv,method,ObjectParser,_format_entity_name,8,36-38,40",
    "pub,method,ObjectParser,parse,8,40-57,218",
    "pub,class,EntityParser,MethodParser,8,60-108,510",
    "pub,class,EntityParser,FunctionParser,8,111-141,371",
    "pub,class,EntityParser,InterfaceParser,8,144-151,116",
    "pub,class,EntityParser,ClassParser,8,154-161,114",
    "pub,class,DepsParser,DepsParserJs,8,164-188,254",
    "prv,method,DepsParserJs,_process_match,8,174-188,152",
    "pub,class,ContentBlock,ContentCodeJs,8,191-239,467",
    "pub,method,ContentCodeJs,parse_content,8,204-239,325",
    "pub,class,ContentCodeJs,ContentCodeTypeScript,8,242-288,443",
    "pub,function,,estimate_tokens,9,7-22,138",
    "pub,class,EntityParser,ClassParser,10,30-40,106",
    "prv,method,ClassParser,__init__,10,32-40,93",
    "pub,class,EntityParser,FunctionParser,10,43-46,54",
    "pub,class,DepsParser,DepsParserPHP,10,49-68,158",
    "prv,method,DepsParserPHP,_process_match,10,61-68,85",
    "pub,class,ContentBlock,ContentCodePHP,10,70-150,737",
    "pub,method,ContentCodePHP,strip_strings,10,91-105,96",
    "pub,method,ContentCodePHP,check_raw_escape,10,108-113,111",
    "pub,method,ContentCodePHP,parse_content,10,115-150,326",
    "pub,class,EntityParser,ClassParser,11,21-49,397",
    "prv,method,ClassParser,__init__,11,23-28,103",
    "pub,method,ClassParser,parse,11,30-49,281",
    "pub,class,EntityParser,FunctionParser,11,52-103,666",
    "prv,method,FunctionParser,_format_entity_name,11,61-62,21",
    "pub,class,DepsParser,DepsParserPython,11,106-127,194",
    "pub,class,ContentBlock,ContentCodePython,11,130-227,1040",
    "pub,method,ContentCodePython,detect_bounds,11,147-190,503",
    "pub,method,ContentCodePython,parse_content,11,192-227,327",
    "pub,class,EntityParser,ModuleParser,12,22-66,552",
    "prv,method,ModuleParser,__init__,12,24-28,88",
    "prv,method,ModuleParser,_process_match,12,30-66,451",
    "pub,class,EntityParser,TraitParser,12,69-83,199",
    "pub,class,EntityParser,TraitImplParser,12,86-109,261",
    "prv,method,TraitImplParser,_format_entity_name,12,104-109,56",
    "pub,class,EntityParser,FunctionParser,12,112-120,132",
    "pub,class,DepsParser,DepsParserRust,12,123-194,576",
    "pub,method,DepsParserRust,process_imports,12,145-183,365",
    "pub,class,ContentBlock,ContentCodeRust,12,199-279,787",
    "pub,method,ContentCodeRust,check_lines_match,12,214-227,171",
    "pub,method,ContentCodeRust,count_chars,12,229-238,109",
    "pub,method,ContentCodeRust,parse_content,12,240-279,343",
    "pub,function,,compute_md5,13,18-19,28",
    "pub,class,,SandwichPack,13,22-274,2379",
    "prv,method,SandwichPack,__init__,13,25-41,183",
    "pub,method,SandwichPack,register_block_class,13,43-46,32",
    "pub,method,SandwichPack,load_block_classes,13,48-63,160",
    "pub,method,SandwichPack,supported_type,13,65-72,84",
    "pub,class,EntityParser,FunctionParser,14,16-45,369",
    "prv,method,FunctionParser,__init__,14,18-25,80",
    "pub,method,FunctionParser,parse,14,27-45,275",
    "pub,class,DepsParser,DepsParserShell,14,48-61,127",
    "prv,method,DepsParserShell,_process_match,14,55-61,68",
    "pub,class,ContentBlock,ContentShellScript,14,64-104,425",
    "pub,method,ContentShellScript,parse_content,14,75-104,306",
    "pub,class,EntityParser,ComponentParser,15,17-39,286",
    "prv,method,ComponentParser,__init__,15,19-22,67",
    "pub,method,ComponentParser,parse,15,24-39,205",
    "pub,class,ContentBlock,ContentCodeVue,15,42-91,480",
    "pub,method,ContentCodeVue,parse_content,15,56-91,326",
    "pub,function,,dump_entities,17,20-24,46",
    "pub,class,,TestParsersBrief,17,27-38,103",
    "pub,method,TestParsersBrief,setUp,17,28-29,15",
    "pub,method,TestParsersBrief,entity_check,17,31-33,52",
    "pub,method,TestParsersBrief,test_rust_parser,17,35-38,24",
    "pub,function,,test_vue_parser,17,62-65,24",
    "pub,function,,test_shell_parser,17,87-90,24",
    "pub,function,,test_python_parser,17,107-110,25",
    "pub,function,,test_function,17,111-112,10",
    "pub,class,,TestClass,17,114-116,18",
    "pub,method,TestClass,test_method,17,115-116,12",
    "pub,function,,test_js_parser,17,130-133,24",
    "pub,function,,test_php_parser,17,165-168,24",
    "pub,function,,test_parse_modules,18,25-40,143",
    "pub,function,,test_protect_modules,18,43-62,100",
    "pub,function,,simpleFunction,19,5-7,16",
    "pub,function,,arrowFunction,19,10-12,22",
    "pub,function,,exprFunction,19,15-17,23",
    "pub,object,,myObject,19,20-26,31",
    "pub,method,myObject,myMethod,19,22-24,5",
    "pub,method,myObject,myComputed,19,31-33,5",
    "pub,object,,module,19,39-45,38",
    "pub,function,,incompleteString,19,42-45,26",
    "pub,object,,s,19,43-50,35",
    "pub,function,,simple_function,20,6-8,17",
    "pub,class,,MyClass,20,11-19,65",
    "pub,method,MyClass,my_method,20,12-14,11",
    "pub,method,MyClass,sqli,20,15-17,8",
    "pub,abstract method,MyClass,my_abstract_method,20,18-18,12",
    "pub,function,,last_function,20,29-30,20",
    "pub,function,,simple_function,21,5-9,28",
    "pub,local_function,,local_inner,21,6-7,11",
    "pub,class,,MyClass,21,12-18,32",
    "pub,method,MyClass,my_method,21,13-14,11",
    "pub,method,MyClass,my_classmethod,21,16-18,12",
    "prv,function,,simple_function,22,3-6,27",
    "prv,function,,raw_string_function,22,9-12,30",
    "prv,function,,comment_function,22,15-18,30",
    "prv,function,,single_comment_function,22,21-24,20",
    "prv,structure,,Outer,22,27-29,17",
    "prv,structure,,Inner,22,31-33,13",
    "prv,function,,incomplete_string,22,36-39,27",
    "prv,interface,Send + Sync,ExampleTrait,22,42-44,34",
    "prv,method,ExampleTrait,trait_method,22,43-50,14",
    "prv,class,,ExampleTrait<Outer>,22,46-50,38",
    "pub,module,,logger,22,53-57,29",
    "prv,function,,logger.logger_function,22,54-56,19",
    "pub,module,,extra_module,22,60-67,47",
    "prv,structure,,extra_module.ExtraStruct,22,61-63,18",
    "prv,function,,extra_module.extra_function,22,64-66,18",
    "prv,class,,Inner,22,69-74,33",
    "prv,async method,Inner,new,22,70-73,15",
    "prv,interface,,LoadEquityData,22,86-94,78",
    "prv,async method,LoadEquityData,load_equity_data,22,87-97,64",
    "prv,class,,LoadEquityData<MySqlDataSource>,22,98-180,741",
    "pub,interface,,MyInterface,23,4-6,18",
    "pub,class,,MyClass,23,8-12,24",
    "pub,function,,code_block,24,17-30,165",
    "prv,function,,_scan_log,24,33-36,47",
    "pub,class,,TestJsParse,24,39-139,991",
    "pub,method,TestJsParse,setUp,24,40-49,129",
    "pub,method,TestJsParse,test_parse_content,24,51-94,368",
    "pub,method,TestJsParse,test_incomplete_cases,24,96-104,82",
    "pub,method,TestJsParse,test_js_template_string_no_escape,24,106-121,162",
    "pub,method,TestJsParse,test_typescript_specific,24,124-139,239",
    "pub,function,,entity_dump,25,13-14,26",
    "pub,function,,code_block,25,17-32,131",
    "pub,class,,TestPhpParse,25,34-68,339",
    "pub,method,TestPhpParse,setUp,25,35-41,75",
    "pub,method,TestPhpParse,test_parse_content,25,43-68,253",
    "pub,function,,code_block,26,17-30,140",
    "pub,class,,TestPyParse,26,32-92,577",
    "pub,method,TestPyParse,setUp,26,33-42,116",
    "pub,method,TestPyParse,test_parse_content,26,44-92,450",
    "pub,function,,code_block,27,17-26,65",
    "prv,function,,_scan_log,27,29-32,47",
    "pub,class,,TestRustParse,27,35-107,647",
    "pub,method,TestRustParse,setUp,27,36-45,117",
    "pub,method,TestRustParse,test_parse_content,27,47-91,378",
    "pub,method,TestRustParse,test_rust_raw_string_no_escape,27,93-107,140"
  ],
  "files": [
    "0,/spack.py,75888932e5c12e41714e582e860150fc,1416,2025-08-07 08:36:29Z",
    "1,/spack_verify.py,36fa555d1a158aeac89f25fe455985d5,1159,2025-08-06 15:48:54Z",
    "2,/lib/code_stripper.py,e6a65dcd56b198354c017c25b6dff95b,2851,2025-08-06 10:30:03Z",
    "3,/lib/content_block.py,b10ee1f821550623fd1633fca4d3b4e7,5672,2025-08-08 15:21:37Z",
    "4,/lib/deps_builder.py,99307811effa026d03af424844d50339,1203,2025-08-08 13:25:05Z",
    "5,/lib/document_block.py,6e968595e8865f1e50c5bd452d8cce6c,328,2025-07-15 12:56:33Z",
    "6,/lib/entity_parser.py,50993ce1b4a16ad954680eea585bd281,3441,2025-08-09 16:28:14Z",
    "7,/lib/iter_regex.py,a40f86df51088fe4cc83f867a6006bb8,1313,2025-08-09 14:31:00Z",
    "8,/lib/js_block.py,67a21d31c69b0ad81a7c92d99809d637,3906,2025-08-09 15:41:29Z",
    "9,/lib/llm_tools.py,203fafd667304f7b3220e0ef5acb5218,208,2025-08-05 09:55:32Z",
    "10,/lib/php_block.py,e1681f6a7e571aac8a6aed107bbe1085,1824,2025-08-09 16:38:40Z",
    "11,/lib/python_block.py,d97712bc7786c74c9082b908adf197ef,3145,2025-08-09 15:31:43Z",
    "12,/lib/rust_block.py,7c7f7b2e335a1ba1fb9b7e857d6812fd,3713,2025-08-08 15:08:42Z",
    "13,/lib/sandwich_pack.py,a0f5aefc26ba4eb1a4f2b45a514e23a2,3304,2025-08-08 06:09:47Z",
    "14,/lib/shellscript_block.py,5098250db40d78a1f024516a76c66acf,1400,2025-08-09 15:21:01Z",
    "15,/lib/vue_block.py,f23a4130b724632fe047a36dcf8362c9,1302,2025-08-09 15:43:36Z",
    "16,/lib/__init__.py,074cf55a834c54634445ffec1561efc5,20,2025-07-15 06:32:56Z",
    "17,/tests/brief_tests.py,e6e22245ddf66bf84452ccf19c84c121,2122,2025-08-09 15:16:19Z",
    "18,/tests/regex_imports_php.py,570e7cea2bb6495deb1a3ddeb96be304,718,2025-08-03 08:01:14Z",
    "19,/tests/test.js,3f4fb5b0b76ccf9e32b7d0fd2fc90f63,355,2025-08-02 09:04:08Z",
    "20,/tests/test.php,216fe13e8200d647134d45b633e5aa49,205,2025-08-06 09:54:23Z",
    "21,/tests/test.py,e66e2fecf8c51c71fa539e202f5787ec,133,2025-08-04 09:40:17Z",
    "22,/tests/test.rs,535d66412b561d4854d66d846b39f452,1691,2025-08-08 15:00:13Z",
    "23,/tests/test.ts,b381efcb43350bd42bb39fb49de0a79a,81,2025-08-02 06:22:30Z",
    "24,/tests/test_js_parse.py,cdf881a06858c32d39d834874bd389ff,1999,2025-08-02 08:08:27Z",
    "25,/tests/test_php_parse.py,6b92921d34ff70d097997cee025fd276,855,2025-08-09 15:47:40Z",
    "26,/tests/test_py_parse.py,74980d75b14cff997096353ba425281a,1230,2025-08-04 08:28:15Z",
    "27,/tests/test_rust_parse.py,c4aaa2335248a4dfdce41e6c9e404de0,1294,2025-08-08 11:25:19Z"
  ],
  "users": []
}